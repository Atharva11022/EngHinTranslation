{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":441417,"sourceType":"datasetVersion","datasetId":200079}],"dockerImageVersionId":25160,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport string\nfrom string import digits\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport re\n\nimport seaborn as sns\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Input, LSTM, Embedding, Dense\nfrom keras.models import Model\n\nprint(os.listdir(\"../input\"))\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\npd.set_option('display.max_colwidth', -1)\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T16:23:25.403350Z","iopub.execute_input":"2023-10-31T16:23:25.403656Z","iopub.status.idle":"2023-10-31T16:23:27.454707Z","shell.execute_reply.started":"2023-10-31T16:23:25.403598Z","shell.execute_reply":"2023-10-31T16:23:27.453954Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"},{"name":"stdout","text":"['Hindi_English_Truncated_Corpus.csv']\n","output_type":"stream"}]},{"cell_type":"code","source":"lines=pd.read_csv(\"../input/Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2023-10-31T16:23:28.600470Z","iopub.execute_input":"2023-10-31T16:23:28.600805Z","iopub.status.idle":"2023-10-31T16:23:29.639010Z","shell.execute_reply.started":"2023-10-31T16:23:28.600747Z","shell.execute_reply":"2023-10-31T16:23:29.638023Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"lines['source'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:30.834145Z","iopub.execute_input":"2023-10-31T16:23:30.834450Z","iopub.status.idle":"2023-10-31T16:23:30.881433Z","shell.execute_reply.started":"2023-10-31T16:23:30.834407Z","shell.execute_reply":"2023-10-31T16:23:30.880614Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"tides        50000\nted          39881\nindic2012    37726\nName: source, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"    lines=lines[lines['source']=='ted']","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:33.638424Z","iopub.execute_input":"2023-10-31T16:23:33.638720Z","iopub.status.idle":"2023-10-31T16:23:33.684858Z","shell.execute_reply.started":"2023-10-31T16:23:33.638662Z","shell.execute_reply":"2023-10-31T16:23:33.684213Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"lines.head(20)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:35.413403Z","iopub.execute_input":"2023-10-31T16:23:35.413710Z","iopub.status.idle":"2023-10-31T16:23:35.433908Z","shell.execute_reply.started":"2023-10-31T16:23:35.413656Z","shell.execute_reply":"2023-10-31T16:23:35.433150Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   source                                                            english_sentence                                                        hindi_sentence\n0   ted    politicians do not have permission to do what needs to be done.             राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .\n1   ted    I'd like to tell you about one such child,                                  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,                  \n3   ted    what we really mean is that they're bad at not paying attention.            हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते                      \n7   ted    And who are we to say, even, that they are wrong                            और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं                    \n13  ted    So there is some sort of justice                                            तो वहाँ न्याय है                                                    \n23  ted    This changed slowly                                                         धीरे धीरे ये सब बदला                                                \n26  ted    were being produced.                                                        उत्पन्न नहीं कि जाती थी.                                            \n30  ted    And you can see, this LED is going to glow.                                 और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।                        \n32  ted    to turn on the lights or to bring him a glass of water,                     लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,                     \n35  ted    Can you imagine saying that?                                                क्या आप ये कल्पना कर सकते है                                        \n37  ted    Three: this is a good road in - right near where our factory is located.    तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षाकृत बेहतर सडक है।     \n39  ted    What's going on?”                                                           क्या हो रहा है ये?”                                                 \n42  ted    There are also financial reforms in rural China.                            ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।                           \n49  ted    the family planning started in Vietnam and they went for smaller families.  वियतनाम में परिवार योजना शुरू हो गई और उनके परिवार छोटे होने लगे।   \n51  ted    I mean, at that time, trust me,                                             मेरा मतलब, उस समय, सही मानिए,                                       \n53  ted    Not only that,                                                              बस वही नहीं,                                                        \n55  ted    humans destroyed the commons that they depended on.                         मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।     \n56  ted    Almost goes to E, but otherwise the play would be over.                     रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.         \n63  ted    So I want to share with you a couple key insights                           मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ                       \n66  ted    Many countries in the [unclear], they need legitimacy.                      [अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चाहिए.                  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ted</td>\n      <td>politicians do not have permission to do what needs to be done.</td>\n      <td>राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह करने कि अनुमति नहीं है .</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ted</td>\n      <td>I'd like to tell you about one such child,</td>\n      <td>मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहूंगी,</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ted</td>\n      <td>what we really mean is that they're bad at not paying attention.</td>\n      <td>हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ted</td>\n      <td>And who are we to say, even, that they are wrong</td>\n      <td>और हम होते कौन हैं यह कहने भी वाले कि वे गलत हैं</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ted</td>\n      <td>So there is some sort of justice</td>\n      <td>तो वहाँ न्याय है</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>ted</td>\n      <td>This changed slowly</td>\n      <td>धीरे धीरे ये सब बदला</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>ted</td>\n      <td>were being produced.</td>\n      <td>उत्पन्न नहीं कि जाती थी.</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>ted</td>\n      <td>And you can see, this LED is going to glow.</td>\n      <td>और जैसा आप देख रहे है, ये एल.ई.डी. जल उठेगी।</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>ted</td>\n      <td>to turn on the lights or to bring him a glass of water,</td>\n      <td>लाईट जलाने के लिए या उनके लिए पानी लाने के लिए,</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>ted</td>\n      <td>Can you imagine saying that?</td>\n      <td>क्या आप ये कल्पना कर सकते है</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>ted</td>\n      <td>Three: this is a good road in - right near where our factory is located.</td>\n      <td>तीसरी: ये हमारी फ़ैक्ट्री के पास की एक अपेक्षाकृत बेहतर सडक है।</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ted</td>\n      <td>What's going on?”</td>\n      <td>क्या हो रहा है ये?”</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>ted</td>\n      <td>There are also financial reforms in rural China.</td>\n      <td>ग्रामीण चीन में आर्थिक नवीनीकरण हुये हैं।</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>ted</td>\n      <td>the family planning started in Vietnam and they went for smaller families.</td>\n      <td>वियतनाम में परिवार योजना शुरू हो गई और उनके परिवार छोटे होने लगे।</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>ted</td>\n      <td>I mean, at that time, trust me,</td>\n      <td>मेरा मतलब, उस समय, सही मानिए,</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>ted</td>\n      <td>Not only that,</td>\n      <td>बस वही नहीं,</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>ted</td>\n      <td>humans destroyed the commons that they depended on.</td>\n      <td>मानवों ने उन ही साझे संसाधनों को नष्ट किया जिन पर वो आधारित थे।</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>ted</td>\n      <td>Almost goes to E, but otherwise the play would be over.</td>\n      <td>रचना करीब करीब ई तक जाती है, मगर तब तो नाटक ख़त्म हो जाएगा.</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>ted</td>\n      <td>So I want to share with you a couple key insights</td>\n      <td>मैं आपके साथ कुछ मुख्य सूत्र बाँटना चाहता हूँ</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>ted</td>\n      <td>Many countries in the [unclear], they need legitimacy.</td>\n      <td>[अस्पष्ट] के बहुत सारे राष्ट्रों को मान्यता चाहिए.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"pd.isnull(lines).sum()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:37.932109Z","iopub.execute_input":"2023-10-31T16:23:37.932393Z","iopub.status.idle":"2023-10-31T16:23:37.955076Z","shell.execute_reply.started":"2023-10-31T16:23:37.932349Z","shell.execute_reply":"2023-10-31T16:23:37.954250Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"source              0\nenglish_sentence    0\nhindi_sentence      0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"lines=lines[~pd.isnull(lines['english_sentence'])]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:39.592247Z","iopub.execute_input":"2023-10-31T16:23:39.592518Z","iopub.status.idle":"2023-10-31T16:23:39.604648Z","shell.execute_reply.started":"2023-10-31T16:23:39.592478Z","shell.execute_reply":"2023-10-31T16:23:39.604032Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"lines.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:41.159421Z","iopub.execute_input":"2023-10-31T16:23:41.159707Z","iopub.status.idle":"2023-10-31T16:23:41.209493Z","shell.execute_reply.started":"2023-10-31T16:23:41.159648Z","shell.execute_reply":"2023-10-31T16:23:41.208621Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"* ### Let us pick any 25000 rows from the dataset.","metadata":{}},{"cell_type":"code","source":"lines=lines.sample(n=25000,random_state=42)\nlines.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:43.025663Z","iopub.execute_input":"2023-10-31T16:23:43.026021Z","iopub.status.idle":"2023-10-31T16:23:43.039082Z","shell.execute_reply.started":"2023-10-31T16:23:43.025959Z","shell.execute_reply":"2023-10-31T16:23:43.038282Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"(25000, 3)"},"metadata":{}}]},{"cell_type":"code","source":"# Lowercase all characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:44.543364Z","iopub.execute_input":"2023-10-31T16:23:44.543639Z","iopub.status.idle":"2023-10-31T16:23:44.592577Z","shell.execute_reply.started":"2023-10-31T16:23:44.543591Z","shell.execute_reply":"2023-10-31T16:23:44.591729Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Remove quotes\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:45.891824Z","iopub.execute_input":"2023-10-31T16:23:45.892144Z","iopub.status.idle":"2023-10-31T16:23:45.996080Z","shell.execute_reply.started":"2023-10-31T16:23:45.892060Z","shell.execute_reply":"2023-10-31T16:23:45.995091Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"exclude = set(string.punctuation) # Set of all special characters\n# Remove all the special characters\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:47.516679Z","iopub.execute_input":"2023-10-31T16:23:47.517017Z","iopub.status.idle":"2023-10-31T16:23:47.946405Z","shell.execute_reply.started":"2023-10-31T16:23:47.516957Z","shell.execute_reply":"2023-10-31T16:23:47.945487Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Remove all numbers from text\nremove_digits = str.maketrans('', '', digits)\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n\n# Remove extra spaces\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\nlines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\nlines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:23:48.887303Z","iopub.execute_input":"2023-10-31T16:23:48.887610Z","iopub.status.idle":"2023-10-31T16:23:49.430127Z","shell.execute_reply.started":"2023-10-31T16:23:48.887555Z","shell.execute_reply":"2023-10-31T16:23:49.429313Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Add start and end tokens to target sequences\nlines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:09:59.003859Z","iopub.execute_input":"2023-10-31T13:09:59.004187Z","iopub.status.idle":"2023-10-31T13:09:59.026549Z","shell.execute_reply.started":"2023-10-31T13:09:59.004127Z","shell.execute_reply":"2023-10-31T13:09:59.025639Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"lines.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:00.872389Z","iopub.execute_input":"2023-10-31T13:10:00.872695Z","iopub.status.idle":"2023-10-31T13:10:00.883618Z","shell.execute_reply.started":"2023-10-31T13:10:00.872640Z","shell.execute_reply":"2023-10-31T13:10:00.882656Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                           \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                 \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                          \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"### Get English and Hindi Vocabulary\nall_eng_words=set()\nfor eng in lines['english_sentence']:\n    for word in eng.split():\n        if word not in all_eng_words:\n            all_eng_words.add(word)\n\nall_hindi_words=set()\nfor hin in lines['hindi_sentence']:\n    for word in hin.split():\n        if word not in all_hindi_words:\n            all_hindi_words.add(word)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:03.438457Z","iopub.execute_input":"2023-10-31T13:10:03.438737Z","iopub.status.idle":"2023-10-31T13:10:03.580544Z","shell.execute_reply.started":"2023-10-31T13:10:03.438695Z","shell.execute_reply":"2023-10-31T13:10:03.579897Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"len(all_eng_words)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:06.145403Z","iopub.execute_input":"2023-10-31T13:10:06.145675Z","iopub.status.idle":"2023-10-31T13:10:06.151005Z","shell.execute_reply.started":"2023-10-31T13:10:06.145635Z","shell.execute_reply":"2023-10-31T13:10:06.150078Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"14030"},"metadata":{}}]},{"cell_type":"code","source":"len(all_hindi_words)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:07.774860Z","iopub.execute_input":"2023-10-31T13:10:07.775150Z","iopub.status.idle":"2023-10-31T13:10:07.779989Z","shell.execute_reply.started":"2023-10-31T13:10:07.775105Z","shell.execute_reply":"2023-10-31T13:10:07.779327Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"17540"},"metadata":{}}]},{"cell_type":"code","source":"lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\nlines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:09.321702Z","iopub.execute_input":"2023-10-31T13:10:09.321983Z","iopub.status.idle":"2023-10-31T13:10:09.407061Z","shell.execute_reply.started":"2023-10-31T13:10:09.321936Z","shell.execute_reply":"2023-10-31T13:10:09.406525Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"lines.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:11.859454Z","iopub.execute_input":"2023-10-31T13:10:11.859738Z","iopub.status.idle":"2023-10-31T13:10:11.872429Z","shell.execute_reply.started":"2023-10-31T13:10:11.859695Z","shell.execute_reply":"2023-10-31T13:10:11.871622Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"       source                                                                           english_sentence                                                                                            hindi_sentence  length_eng_sentence  length_hin_sentence\n82040   ted    we still dont know who her parents are who she is                                          START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END                                   11                   16                 \n85038   ted    no keyboard                                                                                START_ कोई कुंजीपटल नहीं _END                                                                             2                    5                  \n58018   ted    but as far as being a performer                                                            START_ लेकिन एक कलाकार होने के साथ _END                                                                   7                    8                  \n74470   ted    and this particular balloon                                                                START_ और यह खास गुब्बारा _END                                                                            4                    6                  \n122330  ted    and its not as hard as you think integrate climate solutions into all of your innovations  START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END  16                   20                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>82040</th>\n      <td>ted</td>\n      <td>we still dont know who her parents are who she is</td>\n      <td>START_ हम अभी तक नहीं जानते हैं कि उसके मातापिता कौन हैं वह कौन है _END</td>\n      <td>11</td>\n      <td>16</td>\n    </tr>\n    <tr>\n      <th>85038</th>\n      <td>ted</td>\n      <td>no keyboard</td>\n      <td>START_ कोई कुंजीपटल नहीं _END</td>\n      <td>2</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>58018</th>\n      <td>ted</td>\n      <td>but as far as being a performer</td>\n      <td>START_ लेकिन एक कलाकार होने के साथ _END</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>74470</th>\n      <td>ted</td>\n      <td>and this particular balloon</td>\n      <td>START_ और यह खास गुब्बारा _END</td>\n      <td>4</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>122330</th>\n      <td>ted</td>\n      <td>and its not as hard as you think integrate climate solutions into all of your innovations</td>\n      <td>START_ और जितना आपको लगता है यह उतना कठिन नहीं हैअपने सभी नवाचारों में जलवायु समाधान को एकीकृत करें _END</td>\n      <td>16</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"lines[lines['length_eng_sentence']>30].shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:14.089404Z","iopub.execute_input":"2023-10-31T13:10:14.089710Z","iopub.status.idle":"2023-10-31T13:10:14.097670Z","shell.execute_reply.started":"2023-10-31T13:10:14.089653Z","shell.execute_reply":"2023-10-31T13:10:14.096979Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(0, 5)"},"metadata":{}}]},{"cell_type":"code","source":"lines=lines[lines['length_eng_sentence']<=20]\nlines=lines[lines['length_hin_sentence']<=20]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:15.747045Z","iopub.execute_input":"2023-10-31T13:10:15.747362Z","iopub.status.idle":"2023-10-31T13:10:15.758543Z","shell.execute_reply.started":"2023-10-31T13:10:15.747310Z","shell.execute_reply":"2023-10-31T13:10:15.757794Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"lines.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:18.001963Z","iopub.execute_input":"2023-10-31T13:10:18.002301Z","iopub.status.idle":"2023-10-31T13:10:18.007805Z","shell.execute_reply.started":"2023-10-31T13:10:18.002241Z","shell.execute_reply":"2023-10-31T13:10:18.007077Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(24774, 5)"},"metadata":{}}]},{"cell_type":"code","source":"print(\"maximum length of Hindi Sentence \",max(lines['length_hin_sentence']))\nprint(\"maximum length of English Sentence \",max(lines['length_eng_sentence']))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:20.014429Z","iopub.execute_input":"2023-10-31T13:10:20.014713Z","iopub.status.idle":"2023-10-31T13:10:20.021742Z","shell.execute_reply.started":"2023-10-31T13:10:20.014670Z","shell.execute_reply":"2023-10-31T13:10:20.020549Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"maximum length of Hindi Sentence  20\nmaximum length of English Sentence  20\n","output_type":"stream"}]},{"cell_type":"code","source":"max_length_src=max(lines['length_hin_sentence'])\nmax_length_tar=max(lines['length_eng_sentence'])","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:22.302057Z","iopub.execute_input":"2023-10-31T13:10:22.302374Z","iopub.status.idle":"2023-10-31T13:10:22.308429Z","shell.execute_reply.started":"2023-10-31T13:10:22.302328Z","shell.execute_reply":"2023-10-31T13:10:22.307696Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"input_words = sorted(list(all_eng_words))\ntarget_words = sorted(list(all_hindi_words))\nnum_encoder_tokens = len(all_eng_words)\nnum_decoder_tokens = len(all_hindi_words)\nnum_encoder_tokens, num_decoder_tokens","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:24.612437Z","iopub.execute_input":"2023-10-31T13:10:24.612704Z","iopub.status.idle":"2023-10-31T13:10:24.636508Z","shell.execute_reply.started":"2023-10-31T13:10:24.612663Z","shell.execute_reply":"2023-10-31T13:10:24.635714Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(14030, 17540)"},"metadata":{}}]},{"cell_type":"code","source":"num_decoder_tokens += 1 #for zero padding\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:26.419067Z","iopub.execute_input":"2023-10-31T13:10:26.419357Z","iopub.status.idle":"2023-10-31T13:10:26.423080Z","shell.execute_reply.started":"2023-10-31T13:10:26.419313Z","shell.execute_reply":"2023-10-31T13:10:26.422334Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\ntarget_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:29.542921Z","iopub.execute_input":"2023-10-31T13:10:29.543316Z","iopub.status.idle":"2023-10-31T13:10:29.636897Z","shell.execute_reply.started":"2023-10-31T13:10:29.543257Z","shell.execute_reply":"2023-10-31T13:10:29.635872Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\nreverse_target_char_index = dict((i, word) for word, i in target_token_index.items())","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:31.455600Z","iopub.execute_input":"2023-10-31T13:10:31.455878Z","iopub.status.idle":"2023-10-31T13:10:31.468057Z","shell.execute_reply.started":"2023-10-31T13:10:31.455836Z","shell.execute_reply":"2023-10-31T13:10:31.467268Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"lines = shuffle(lines)\nlines.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:33.475972Z","iopub.execute_input":"2023-10-31T13:10:33.476287Z","iopub.status.idle":"2023-10-31T13:10:33.496336Z","shell.execute_reply.started":"2023-10-31T13:10:33.476228Z","shell.execute_reply":"2023-10-31T13:10:33.495391Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"       source                                   english_sentence                                                    hindi_sentence  length_eng_sentence  length_hin_sentence\n90152   ted    the rabbis describe this as being like a king      START_ रब्बी इसे एक राजा की तरह होना वर्णित करते हैं _END         9                    12                 \n52658   ted    the very hardtoserve places their neighbors        START_ दूरदराज़ इलाकों में उनके पड़ोसियों तक _END                 6                    8                  \n73247   ted    by people in extreme cold in subzero temperatures  START_ लोगो द्वारा चरम ठंड मे शून्य से नीचे के तापक्रम में। _END  8                    13                 \n3142    ted    but the extension of the logic is                  START_ लेकिन इस तर्क का विस्तार है _END                           7                    8                  \n35897   ted    when i walked across afghanistan                   START_ जब मैं अफगानिस्तान के पार गया _END                         5                    8                  \n104170  ted    and thats the name of the owner of the card        START_ और यह है कार्ड के मालिक का नाम है _END                     10                   11                 \n11356   ted    but its that contempt                              START_ पर यह वही तिरस्कार है _END                                 4                    7                  \n90080   ted    such as this jarshaped sign                        START_ जैसे कि यह जग जैसा चिन्ह। _END                             5                    8                  \n21587   ted    because all i had read were books                  START_ चूंकि मैं वही पुस्तकें पढ़ा करती थी _END                   7                    9                  \n51518   ted    your link is just as good as your link             START_ आपका लिंक आपके लिंक जितना ही अच्छा है _END                 9                    10                 ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>english_sentence</th>\n      <th>hindi_sentence</th>\n      <th>length_eng_sentence</th>\n      <th>length_hin_sentence</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>90152</th>\n      <td>ted</td>\n      <td>the rabbis describe this as being like a king</td>\n      <td>START_ रब्बी इसे एक राजा की तरह होना वर्णित करते हैं _END</td>\n      <td>9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>52658</th>\n      <td>ted</td>\n      <td>the very hardtoserve places their neighbors</td>\n      <td>START_ दूरदराज़ इलाकों में उनके पड़ोसियों तक _END</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>73247</th>\n      <td>ted</td>\n      <td>by people in extreme cold in subzero temperatures</td>\n      <td>START_ लोगो द्वारा चरम ठंड मे शून्य से नीचे के तापक्रम में। _END</td>\n      <td>8</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3142</th>\n      <td>ted</td>\n      <td>but the extension of the logic is</td>\n      <td>START_ लेकिन इस तर्क का विस्तार है _END</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>35897</th>\n      <td>ted</td>\n      <td>when i walked across afghanistan</td>\n      <td>START_ जब मैं अफगानिस्तान के पार गया _END</td>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>104170</th>\n      <td>ted</td>\n      <td>and thats the name of the owner of the card</td>\n      <td>START_ और यह है कार्ड के मालिक का नाम है _END</td>\n      <td>10</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>11356</th>\n      <td>ted</td>\n      <td>but its that contempt</td>\n      <td>START_ पर यह वही तिरस्कार है _END</td>\n      <td>4</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>90080</th>\n      <td>ted</td>\n      <td>such as this jarshaped sign</td>\n      <td>START_ जैसे कि यह जग जैसा चिन्ह। _END</td>\n      <td>5</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>21587</th>\n      <td>ted</td>\n      <td>because all i had read were books</td>\n      <td>START_ चूंकि मैं वही पुस्तकें पढ़ा करती थी _END</td>\n      <td>7</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>51518</th>\n      <td>ted</td>\n      <td>your link is just as good as your link</td>\n      <td>START_ आपका लिंक आपके लिंक जितना ही अच्छा है _END</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Split the data into train and test","metadata":{}},{"cell_type":"code","source":"X, y = lines['english_sentence'], lines['hindi_sentence']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\nX_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:36.878032Z","iopub.execute_input":"2023-10-31T13:10:36.878346Z","iopub.status.idle":"2023-10-31T13:10:36.891780Z","shell.execute_reply.started":"2023-10-31T13:10:36.878295Z","shell.execute_reply":"2023-10-31T13:10:36.890884Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"((19819,), (4955,))"},"metadata":{}}]},{"cell_type":"markdown","source":"### Let us save this data","metadata":{}},{"cell_type":"code","source":"X_train.to_pickle('X_train.pkl')\nX_test.to_pickle('X_test.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:39.436363Z","iopub.execute_input":"2023-10-31T13:10:39.436686Z","iopub.status.idle":"2023-10-31T13:10:39.615117Z","shell.execute_reply.started":"2023-10-31T13:10:39.436628Z","shell.execute_reply":"2023-10-31T13:10:39.614163Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def generate_batch(X = X_train, y = y_train, batch_size = 128):\n    ''' Generate a batch of data '''\n    while True:\n        for j in range(0, len(X), batch_size):\n            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n                for t, word in enumerate(input_text.split()):\n                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n                for t, word in enumerate(target_text.split()):\n                    if t<len(target_text.split())-1:\n                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n                    if t>0:\n                        # decoder target sequence (one hot encoded)\n                        # does not include the START_ token\n                        # Offset by one timestep\n                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n            yield([encoder_input_data, decoder_input_data], decoder_target_data)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:44.741785Z","iopub.execute_input":"2023-10-31T13:10:44.742105Z","iopub.status.idle":"2023-10-31T13:10:44.750179Z","shell.execute_reply.started":"2023-10-31T13:10:44.742045Z","shell.execute_reply":"2023-10-31T13:10:44.749312Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Encoder-Decoder Architecture","metadata":{}},{"cell_type":"code","source":"latent_dim=300","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:47.565381Z","iopub.execute_input":"2023-10-31T13:10:47.565674Z","iopub.status.idle":"2023-10-31T13:10:47.569163Z","shell.execute_reply.started":"2023-10-31T13:10:47.565632Z","shell.execute_reply":"2023-10-31T13:10:47.568411Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"# Encoder\nencoder_inputs = Input(shape=(None,))\nenc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\nencoder_lstm = LSTM(latent_dim, return_state=True)\nencoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n# We discard `encoder_outputs` and only keep the states.\nencoder_states = [state_h, state_c]","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:49.954088Z","iopub.execute_input":"2023-10-31T13:10:49.954426Z","iopub.status.idle":"2023-10-31T13:10:50.517227Z","shell.execute_reply.started":"2023-10-31T13:10:49.954372Z","shell.execute_reply":"2023-10-31T13:10:50.516349Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up the decoder, using `encoder_states` as initial state.\ndecoder_inputs = Input(shape=(None,))\ndec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\ndec_emb = dec_emb_layer(decoder_inputs)\n# We set up our decoder to return full output sequences,\n# and to return internal states as well. We don't use the\n# return states in the training model, but we will use them in inference.\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\ndecoder_outputs, _, _ = decoder_lstm(dec_emb,\n                                     initial_state=encoder_states)\ndecoder_dense = Dense(num_decoder_tokens, activation='softmax')\ndecoder_outputs = decoder_dense(decoder_outputs)\n\n# Define the model that will turn\n# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:52.660030Z","iopub.execute_input":"2023-10-31T13:10:52.660326Z","iopub.status.idle":"2023-10-31T13:10:53.086674Z","shell.execute_reply.started":"2023-10-31T13:10:52.660282Z","shell.execute_reply":"2023-10-31T13:10:53.085800Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='rmsprop', loss='categorical_crossentropy')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:55.201790Z","iopub.execute_input":"2023-10-31T13:10:55.202107Z","iopub.status.idle":"2023-10-31T13:10:55.241184Z","shell.execute_reply.started":"2023-10-31T13:10:55.202049Z","shell.execute_reply":"2023-10-31T13:10:55.240617Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:57.358735Z","iopub.execute_input":"2023-10-31T13:10:57.359074Z","iopub.status.idle":"2023-10-31T13:10:57.364959Z","shell.execute_reply.started":"2023-10-31T13:10:57.359014Z","shell.execute_reply":"2023-10-31T13:10:57.364086Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            (None, None)         0                                            \n__________________________________________________________________________________________________\nembedding_1 (Embedding)         (None, None, 300)    4209000     input_1[0][0]                    \n__________________________________________________________________________________________________\nembedding_2 (Embedding)         (None, None, 300)    5262300     input_2[0][0]                    \n__________________________________________________________________________________________________\nlstm_1 (LSTM)                   [(None, 300), (None, 721200      embedding_1[0][0]                \n__________________________________________________________________________________________________\nlstm_2 (LSTM)                   [(None, None, 300),  721200      embedding_2[0][0]                \n                                                                 lstm_1[0][1]                     \n                                                                 lstm_1[0][2]                     \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, None, 17541)  5279841     lstm_2[0][0]                     \n==================================================================================================\nTotal params: 16,193,541\nTrainable params: 16,193,541\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"train_samples = len(X_train)\nval_samples = len(X_test)\nbatch_size = 128\nepochs = 100","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:10:59.746807Z","iopub.execute_input":"2023-10-31T13:10:59.747104Z","iopub.status.idle":"2023-10-31T13:10:59.750735Z","shell.execute_reply.started":"2023-10-31T13:10:59.747062Z","shell.execute_reply":"2023-10-31T13:10:59.749950Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n                    steps_per_epoch = train_samples//batch_size,\n                    epochs=epochs,\n                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n                    validation_steps = val_samples//batch_size)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-31T13:11:02.137899Z","iopub.execute_input":"2023-10-31T13:11:02.138184Z","iopub.status.idle":"2023-10-31T15:12:30.936629Z","shell.execute_reply.started":"2023-10-31T13:11:02.138141Z","shell.execute_reply":"2023-10-31T15:12:30.935825Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nDeprecated in favor of operator or tf.math.divide.\nEpoch 1/100\n154/154 [==============================] - 77s 501ms/step - loss: 6.4359 - val_loss: 6.0882\nEpoch 2/100\n154/154 [==============================] - 73s 471ms/step - loss: 5.8295 - val_loss: 5.7496\nEpoch 3/100\n154/154 [==============================] - 73s 474ms/step - loss: 5.4741 - val_loss: 5.5757\nEpoch 4/100\n154/154 [==============================] - 73s 473ms/step - loss: 5.2372 - val_loss: 5.4988\nEpoch 5/100\n154/154 [==============================] - 73s 472ms/step - loss: 5.0407 - val_loss: 5.4183\nEpoch 6/100\n154/154 [==============================] - 73s 472ms/step - loss: 4.8614 - val_loss: 5.3537\nEpoch 7/100\n154/154 [==============================] - 73s 471ms/step - loss: 4.6930 - val_loss: 5.2993\nEpoch 8/100\n154/154 [==============================] - 73s 471ms/step - loss: 4.5353 - val_loss: 5.2637\nEpoch 9/100\n154/154 [==============================] - 73s 471ms/step - loss: 4.3854 - val_loss: 5.2313\nEpoch 10/100\n154/154 [==============================] - 72s 470ms/step - loss: 4.2369 - val_loss: 5.2209\nEpoch 11/100\n154/154 [==============================] - 73s 471ms/step - loss: 4.0967 - val_loss: 5.2116\nEpoch 12/100\n154/154 [==============================] - 73s 473ms/step - loss: 3.9590 - val_loss: 5.2232\nEpoch 13/100\n154/154 [==============================] - 73s 475ms/step - loss: 3.8247 - val_loss: 5.2321\nEpoch 14/100\n154/154 [==============================] - 73s 474ms/step - loss: 3.6979 - val_loss: 5.2396\nEpoch 15/100\n154/154 [==============================] - 73s 474ms/step - loss: 3.5697 - val_loss: 5.2661\nEpoch 16/100\n154/154 [==============================] - 73s 474ms/step - loss: 3.4461 - val_loss: 5.2880\nEpoch 17/100\n154/154 [==============================] - 73s 473ms/step - loss: 3.3223 - val_loss: 5.3120\nEpoch 18/100\n154/154 [==============================] - 73s 475ms/step - loss: 3.2041 - val_loss: 5.3502\nEpoch 19/100\n154/154 [==============================] - 73s 475ms/step - loss: 3.0878 - val_loss: 5.3684\nEpoch 20/100\n154/154 [==============================] - 73s 474ms/step - loss: 2.9731 - val_loss: 5.4091\nEpoch 21/100\n154/154 [==============================] - 73s 474ms/step - loss: 2.8620 - val_loss: 5.4486\nEpoch 22/100\n154/154 [==============================] - 73s 474ms/step - loss: 2.7524 - val_loss: 5.4887\nEpoch 23/100\n154/154 [==============================] - 73s 473ms/step - loss: 2.6441 - val_loss: 5.5227\nEpoch 24/100\n154/154 [==============================] - 73s 474ms/step - loss: 2.5413 - val_loss: 5.5708\nEpoch 25/100\n154/154 [==============================] - 73s 474ms/step - loss: 2.4382 - val_loss: 5.6193\nEpoch 26/100\n154/154 [==============================] - 73s 472ms/step - loss: 2.3389 - val_loss: 5.6595\nEpoch 27/100\n154/154 [==============================] - 73s 472ms/step - loss: 2.2416 - val_loss: 5.7230\nEpoch 28/100\n154/154 [==============================] - 73s 472ms/step - loss: 2.1466 - val_loss: 5.7623\nEpoch 29/100\n154/154 [==============================] - 73s 473ms/step - loss: 2.0539 - val_loss: 5.8194\nEpoch 30/100\n154/154 [==============================] - 73s 473ms/step - loss: 1.9656 - val_loss: 5.8529\nEpoch 31/100\n154/154 [==============================] - 73s 473ms/step - loss: 1.8789 - val_loss: 5.8938\nEpoch 32/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.7954 - val_loss: 5.9549\nEpoch 33/100\n154/154 [==============================] - 73s 473ms/step - loss: 1.7203 - val_loss: 6.0056\nEpoch 34/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.6434 - val_loss: 6.0604\nEpoch 35/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.5694 - val_loss: 6.0872\nEpoch 36/100\n154/154 [==============================] - 73s 473ms/step - loss: 1.4993 - val_loss: 6.1412\nEpoch 37/100\n154/154 [==============================] - 73s 473ms/step - loss: 1.4296 - val_loss: 6.1880\nEpoch 38/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.3667 - val_loss: 6.2401\nEpoch 39/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.3041 - val_loss: 6.2709\nEpoch 40/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.2468 - val_loss: 6.3023\nEpoch 41/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.1885 - val_loss: 6.3489\nEpoch 42/100\n154/154 [==============================] - 73s 473ms/step - loss: 1.1364 - val_loss: 6.3979\nEpoch 43/100\n154/154 [==============================] - 73s 474ms/step - loss: 1.0857 - val_loss: 6.4365\nEpoch 44/100\n154/154 [==============================] - 73s 472ms/step - loss: 1.0384 - val_loss: 6.4825\nEpoch 45/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.9899 - val_loss: 6.5274\nEpoch 46/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.9438 - val_loss: 6.5517\nEpoch 47/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.9002 - val_loss: 6.6030\nEpoch 48/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.8626 - val_loss: 6.6384\nEpoch 49/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.8281 - val_loss: 6.6704\nEpoch 50/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.7924 - val_loss: 6.7001\nEpoch 51/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.7589 - val_loss: 6.7528\nEpoch 52/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.7274 - val_loss: 6.7722\nEpoch 53/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.6945 - val_loss: 6.7891\nEpoch 54/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.6683 - val_loss: 6.8353\nEpoch 55/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.6406 - val_loss: 6.8863\nEpoch 56/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.6161 - val_loss: 6.8823\nEpoch 57/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.5905 - val_loss: 6.9308\nEpoch 58/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.5700 - val_loss: 6.9531\nEpoch 59/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.5456 - val_loss: 6.9800\nEpoch 60/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.5235 - val_loss: 7.0079\nEpoch 61/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.5028 - val_loss: 7.0318\nEpoch 62/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.4836 - val_loss: 7.0366\nEpoch 63/100\n154/154 [==============================] - 73s 471ms/step - loss: 0.4677 - val_loss: 7.0673\nEpoch 64/100\n154/154 [==============================] - 72s 471ms/step - loss: 0.4474 - val_loss: 7.1031\nEpoch 65/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.4303 - val_loss: 7.1097\nEpoch 66/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.4154 - val_loss: 7.1361\nEpoch 67/100\n154/154 [==============================] - 72s 471ms/step - loss: 0.4013 - val_loss: 7.1522\nEpoch 68/100\n154/154 [==============================] - 73s 471ms/step - loss: 0.3872 - val_loss: 7.1925\nEpoch 69/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.3716 - val_loss: 7.2030\nEpoch 70/100\n154/154 [==============================] - 73s 471ms/step - loss: 0.3615 - val_loss: 7.2159\nEpoch 71/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.3490 - val_loss: 7.2323\nEpoch 72/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.3370 - val_loss: 7.2301\nEpoch 73/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.3289 - val_loss: 7.2422\nEpoch 74/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.3184 - val_loss: 7.2560\nEpoch 75/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.3093 - val_loss: 7.2671\nEpoch 76/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2987 - val_loss: 7.2914\nEpoch 77/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2896 - val_loss: 7.3054\nEpoch 78/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2818 - val_loss: 7.3282\nEpoch 79/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2738 - val_loss: 7.3235\nEpoch 80/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.2662 - val_loss: 7.3544\nEpoch 81/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2582 - val_loss: 7.3514\nEpoch 82/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2504 - val_loss: 7.3707\nEpoch 83/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.2426 - val_loss: 7.3849\nEpoch 84/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2373 - val_loss: 7.3874\nEpoch 85/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.2249 - val_loss: 7.4025\nEpoch 87/100\n154/154 [==============================] - 73s 471ms/step - loss: 0.2178 - val_loss: 7.4145\nEpoch 88/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.2122 - val_loss: 7.4183\nEpoch 89/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.2073 - val_loss: 7.4344\nEpoch 90/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.2015 - val_loss: 7.4533\nEpoch 91/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.1961 - val_loss: 7.4593\nEpoch 92/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.1923 - val_loss: 7.4727\nEpoch 93/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.1859 - val_loss: 7.4795\nEpoch 94/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.1825 - val_loss: 7.4792\nEpoch 95/100\n154/154 [==============================] - 73s 474ms/step - loss: 0.1763 - val_loss: 7.4856\nEpoch 96/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.1719 - val_loss: 7.4926\nEpoch 97/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.1687 - val_loss: 7.4955\nEpoch 98/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.1643 - val_loss: 7.5178\nEpoch 99/100\n154/154 [==============================] - 73s 472ms/step - loss: 0.1609 - val_loss: 7.5186\nEpoch 100/100\n154/154 [==============================] - 73s 473ms/step - loss: 0.1568 - val_loss: 7.5361\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x79c9ace8df98>"},"metadata":{}}]},{"cell_type":"code","source":"model.save_weights('nmt_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T16:22:59.327458Z","iopub.execute_input":"2023-10-31T16:22:59.327767Z","iopub.status.idle":"2023-10-31T16:22:59.469142Z","shell.execute_reply.started":"2023-10-31T16:22:59.327720Z","shell.execute_reply":"2023-10-31T16:22:59.467994Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1c69aa2130f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nmt_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"],"ename":"NameError","evalue":"name 'model' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Encode the input sequence to get the \"thought vectors\"\nencoder_model = Model(encoder_inputs, encoder_states)\n\n# Decoder setup\n# Below tensors will hold the states of the previous time step\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n\ndec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n\n# To predict the next word in the sequence, set the initial states to the states from the previous time step\ndecoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\ndecoder_states2 = [state_h2, state_c2]\ndecoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n\n# Final decoder model\ndecoder_model = Model(\n    [decoder_inputs] + decoder_states_inputs,\n    [decoder_outputs2] + decoder_states2)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:28:48.109216Z","iopub.execute_input":"2023-10-16T17:28:48.109786Z","iopub.status.idle":"2023-10-16T17:28:48.336175Z","shell.execute_reply.started":"2023-10-16T17:28:48.109732Z","shell.execute_reply":"2023-10-16T17:28:48.335387Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def decode_sequence(input_seq):\n    # Encode the input as state vectors.\n    states_value = encoder_model.predict(input_seq)\n    # Generate empty target sequence of length 1.\n    target_seq = np.zeros((1,1))\n    # Populate the first character of target sequence with the start character.\n    target_seq[0, 0] = target_token_index['START_']\n\n    # Sampling loop for a batch of sequences\n    # (to simplify, here we assume a batch of size 1).\n    stop_condition = False\n    decoded_sentence = ''\n    while not stop_condition:\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n\n        # Sample a token\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += ' '+sampled_char\n\n        # Exit condition: either hit max length\n        # or find stop character.\n        if (sampled_char == '_END' or\n           len(decoded_sentence) > 50):\n            stop_condition = True\n\n        # Update the target sequence (of length 1).\n        target_seq = np.zeros((1,1))\n        target_seq[0, 0] = sampled_token_index\n\n        # Update states\n        states_value = [h, c]\n\n    return decoded_sentence","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:20.305696Z","iopub.execute_input":"2023-10-16T17:29:20.305979Z","iopub.status.idle":"2023-10-16T17:29:20.312005Z","shell.execute_reply.started":"2023-10-16T17:29:20.305925Z","shell.execute_reply":"2023-10-16T17:29:20.311179Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"train_gen = generate_batch(X_train, y_train, batch_size = 1)\nk=-1\n","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:41.299105Z","iopub.execute_input":"2023-10-16T17:29:41.299375Z","iopub.status.idle":"2023-10-16T17:29:41.303264Z","shell.execute_reply.started":"2023-10-16T17:29:41.299324Z","shell.execute_reply":"2023-10-16T17:29:41.302268Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:44.640996Z","iopub.execute_input":"2023-10-16T17:29:44.641267Z","iopub.status.idle":"2023-10-16T17:29:44.981328Z","shell.execute_reply.started":"2023-10-16T17:29:44.641215Z","shell.execute_reply":"2023-10-16T17:29:44.980282Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Input English sentence: without this ability\nActual Hindi Translation:  इस योग्यता के बिना \nPredicted Hindi Translation:  इस योग्यता के बिना \n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:50.431907Z","iopub.execute_input":"2023-10-16T17:29:50.432523Z","iopub.status.idle":"2023-10-16T17:29:50.513444Z","shell.execute_reply.started":"2023-10-16T17:29:50.432440Z","shell.execute_reply":"2023-10-16T17:29:50.512633Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Input English sentence: now if you think thats fabulous this is one of my great favorites\nActual Hindi Translation:  अगर वह शानदार था तो यह मेरा पसंदीदा है \nPredicted Hindi Translation:  अगर वह ये है कि यह मेरा पसंदीदा हैं तो बहुत ही\n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:53.611057Z","iopub.execute_input":"2023-10-16T17:29:53.611331Z","iopub.status.idle":"2023-10-16T17:29:53.664678Z","shell.execute_reply.started":"2023-10-16T17:29:53.611279Z","shell.execute_reply":"2023-10-16T17:29:53.663708Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Input English sentence: and they also make really really good stage actors\nActual Hindi Translation:  वे वास्तव में बहुत अच्छे मंच अभिनेता भी बन सकते है \nPredicted Hindi Translation:  वे वास्तव में बहुत अच्छे मंच का अनियमितताओं का उद\n","output_type":"stream"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:55.907249Z","iopub.execute_input":"2023-10-16T17:29:55.907729Z","iopub.status.idle":"2023-10-16T17:29:55.983675Z","shell.execute_reply.started":"2023-10-16T17:29:55.907469Z","shell.execute_reply":"2023-10-16T17:29:55.982699Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"Input English sentence: oh youve got a question for me okay\nActual Hindi Translation:  ओह आप मेरे से कोइ प्रश्न करना चाहते है \nPredicted Hindi Translation:  ओह आप मेरे से कोइ से एक करने की बात करना न देना \n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:35:20.527253Z","iopub.execute_input":"2023-10-16T17:35:20.527567Z","iopub.status.idle":"2023-10-16T17:35:20.767738Z","shell.execute_reply.started":"2023-10-16T17:35:20.527482Z","shell.execute_reply":"2023-10-16T17:35:20.766402Z"},"trusted":true},"execution_count":57,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-57-f4dd016494a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Preprocess the input sentence if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Tokenize and encode the input sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_input_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Use the decode_sequence function to translate the sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'encode_input_sentence' is not defined"],"ename":"NameError","evalue":"name 'encode_input_sentence' is not defined","output_type":"error"}]},{"cell_type":"code","source":"k+=1\n(input_seq, actual_output), _ = next(train_gen)\ndecoded_sentence = decode_sequence(input_seq)\nprint('Input English sentence:', X_train[k:k+1].values[0])\nprint('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\nprint('Predicted Hindi Translation:', decoded_sentence[:-4])","metadata":{"execution":{"iopub.status.busy":"2023-10-16T17:29:58.473702Z","iopub.execute_input":"2023-10-16T17:29:58.473986Z","iopub.status.idle":"2023-10-16T17:29:58.529025Z","shell.execute_reply.started":"2023-10-16T17:29:58.473922Z","shell.execute_reply":"2023-10-16T17:29:58.528079Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Input English sentence: that building trust takes a lot of time\nActual Hindi Translation:  कि उनका विश्वास ग्रहण करने में बहुत वक्त लगता है \nPredicted Hindi Translation:  जो कि उनका बहुत कुछ अलग करना और ऊपर है \n","output_type":"stream"}]}]}